{"title":"The Toronto Workshop on Reproducibility","markdown":{"yaml":{"title":"The Toronto Workshop on Reproducibility","description":"Notes and reflections on a workshop about reproducibility in applied statistics.\n","author":[{"name":"Rohan Alexander","url":{"rohanalexander.com":{}}}],"date":"2021-02-28","output":{"distill::distill_article":{"self_contained":false,"toc":true,"toc_depth":3}},"draft":true,"collections":{"posts":{"citations":false}}},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\n\nOn 25 and 26 February 2021, I hosted the Toronto Workshop on Reproducibility. This was an online event with 35 speakers that 1,284 people signed up for. In the end we averaged around 50 attendees at any one time in the Zoom room, with another 20 on the YouTube live-stream. Talks were recorded and posted to YouTube, and as of today (two days after) the most popular one has been viewed 73 times.\n\nIn this post I will first provide a brief summary of the talks, then discuss attendance. I will provide my view on aspects that were good and bad. And finally detail next steps.\n\n\n## Talks\n\nI first invited keynote speakers and then invited talks from folks that were known to me. I put out a call on Twitter for recommendations of folks that were traditionally overlooked in applied statistics. After establishing that core, I then opened invited applications to speak more generally. A few speakers contacted me asking if they could speak and finally, I specifically invited two undergrads to speak.\n\nThere was a wide variety of talks, including some that would not be out of place at JSM, through to collections of personal anecdotes. The standard of the talks was uniformly high, however the order was dictated more by timezone of the presenter, rather than topic and so there were considerable differences between neighbouring talks.\n\n### Keynotes\n\nThe keynotes were given by Eva Vivalt, Mine Çetinkaya-Rundel, and Riana Minocher. \n\n- Eva [discussed](https://youtu.be/0WZUzf2oSGY) a platform that she created for gathering forecasts of the results of work that will be conducted. For instance, if a survey is being sent to understand the effect of education on income, one could use Eva's platform to first understand expectations of what that survey will find. \n- Mine [discussed](https://youtu.be/ANH2tv2vkew) the evolution of R Markdown, and her use of it in teaching. She showed how R Markdown has become indispensable and highlighted ways in which this would continue to evolve in the future.\n- Riana [discussed](https://youtu.be/O3t8TwWeli0) a recent paper of hers in which she evaluated the extent to which papers in social learning are able to be reproduced. \n\n\n### Invited talks\n\n- Amber Simpson discussed the repeatability and reproducibility of imaging biomarkers.\n- Andrés Cruz discussed an RStudio addin to supervise fuzzy joins. \n- Annie Collins discussed the extent of markers of open code and open data in medRxiv.\n- Emily Riederer discussed `convo` R package, which aids in the creation, upkeep, and application of controlled vocabularies.\n- Florencia D'Andrea discussed ReproHack, which is a hackathon-style event focused on the reproducibility of research results. \n- Garret Christensen discussed a recent paper looking at survey evidence on attitudes, norms and behavior in the social sciences towards open science. \n- Jake Bowers discussed proposals to adjust scientific norms of reproducibility and pre-registration to the policy context.\n- John Blischak discussed the `workflowr` R package\n- Julia Schulte-Cloos introduced a template package in R that allows users without any prior knowledge of R Markdown to implement reproducible research practices in their scientific workflows. \n- Lauren Kennedy discussed case studies of how and where challenges with preparing survey data appear in practice. \n- Larry Fenn and Meghan Hoyer discussed AP DataKit, which is an open-source command-line tool designed to better structure and manage projects, and more generally, talk about creating sane, reproducible workflows.\n- Mauricio Vargas Sepúlveda and Nicolas Didier discussed an attempt to analyze the nature and quality of civil society organizations' contributions to develop evidence for policymaking process from reproducibility perspective.  \n- Monica Alexander discussed some brief reflections from research, consulting, and teaching experiences that have led to overcoming barriers to sharing code and to help others do the same.  \n- Nancy Reid discussed whether p-values are contributing to a crisis in replicability and reproducibility, with emphasis on the role of inferential theory in helping to clarify the arguments.\n- Nick Radcliffe discussed an approach to the challenges of ensuring the correctness and robustness of results in an environment where neither code nor input data can be opened up for review and even outputs need to be subject to disclosure control to reduce further any risks to privacy. \n- Radu Craiu discussed reproducibility in the context of statistical sciences.\n- Ryan Briggs discussed how 'o-ring' production functions work and draws out lessons for applied researchers.\n- Sharla Gelfand discussed what components are needed to make a good reproducible example to maximize your ability to get help (and to help yourself!), strategies for coming up with an example and testing its reproducibility, and why you should care about making one.\n- Shemra Rizzo shared her experience working towards reliable, replicable and reproducible studies using EHR licensed data.\n- Shiro Kuriwaki showed how new features of the [dataverse](https://github.com/IQSS/dataverse-client-r) R package facilitate reproducibility in empirical, substantive projects. \n- Simeon Carstens gave an introduction to Nix, show in a live demo how to set up a fully reproducible software environment and compare Nix to existing solutions such as virtual environments and Docker.\n- Tiffany Timbers presented examples of how UBC deeply motivate, effectively instruct and provide ample practice opportunities to our Master of Data Science students to effectively engage them in learning about reproducibility.\n- Tom Barton reproduced Surridge, 2016, 'Education and liberalism: pursuing the link', *Oxford Review of Education*, 42:2, pp. 146-164, using the 1970 British Cohort Study (BCS70), instead using a difference-in-difference regression approach with more waves of data. \n- Tyler Girard discussed how individual and group exercises centered around the replication of existing datasets and analyses offer a flexible tool for experiential learning. \n- Wendy Duff discussed reproducibility in the context of information.\n- Wijdan Tariq undertook a narrow replication of Caicedo, 2019, 'The Mission: Human Capital Transmission, Economic Persistence, and Culture in South America', *Quarterly Journal of Economics*\n- Yanbo Tang showed that commonly held beliefs regarding the distribution of p-values are misleading when the variance or location of the test statistic are not well-calibrated or when the higher order cumulants of the test statistic are not negligible. \n\n\n## Attendance\n\n```{r,, warning = FALSE, message = FALSE, echo=FALSE}\nlibrary(tidyverse)\n\nread_csv(\"attendence.csv\") %>% \n  mutate(Day = if_else(Day == 1, \"Thursday\", \"Friday\")) %>% \n  ggplot() +\n  geom_point(aes(x = Check, y = Number, color = Day)) +\n  facet_wrap(vars(Type)) +\n  theme_classic() + \n  scale_color_brewer(palette = \"Set1\")\n```\n\n\n\n\n## What worked\n\n- Undergraduate participation. I integrated two undergrad presentations into the main content. Both were exceptional and received very well by the audience.\n- YouTube livestream. I only added this at the last minute because I was worried we might go over the 300-person limit in Zoom. In the end we didn't have a worry about that, but the livestream was very popular. Some people said it was because that way they could keep it on in the background while doing other things (YouTube has better volume control than Zoom).\n- Questions. There was some concern about a lack of time for questions, but in general folks were hesitant to ask questions.\n\n\n## What didn't\n\n- I needed more chairs.\n- More organization.\n- Slack was okay.\n- We didn't really do any 'networking' type events.\n- Funding.s\n- We needed more time.\n\n## Next steps\n\n\n","srcMarkdownNoYaml":"\n\n\n## Introduction\n\nOn 25 and 26 February 2021, I hosted the Toronto Workshop on Reproducibility. This was an online event with 35 speakers that 1,284 people signed up for. In the end we averaged around 50 attendees at any one time in the Zoom room, with another 20 on the YouTube live-stream. Talks were recorded and posted to YouTube, and as of today (two days after) the most popular one has been viewed 73 times.\n\nIn this post I will first provide a brief summary of the talks, then discuss attendance. I will provide my view on aspects that were good and bad. And finally detail next steps.\n\n\n## Talks\n\nI first invited keynote speakers and then invited talks from folks that were known to me. I put out a call on Twitter for recommendations of folks that were traditionally overlooked in applied statistics. After establishing that core, I then opened invited applications to speak more generally. A few speakers contacted me asking if they could speak and finally, I specifically invited two undergrads to speak.\n\nThere was a wide variety of talks, including some that would not be out of place at JSM, through to collections of personal anecdotes. The standard of the talks was uniformly high, however the order was dictated more by timezone of the presenter, rather than topic and so there were considerable differences between neighbouring talks.\n\n### Keynotes\n\nThe keynotes were given by Eva Vivalt, Mine Çetinkaya-Rundel, and Riana Minocher. \n\n- Eva [discussed](https://youtu.be/0WZUzf2oSGY) a platform that she created for gathering forecasts of the results of work that will be conducted. For instance, if a survey is being sent to understand the effect of education on income, one could use Eva's platform to first understand expectations of what that survey will find. \n- Mine [discussed](https://youtu.be/ANH2tv2vkew) the evolution of R Markdown, and her use of it in teaching. She showed how R Markdown has become indispensable and highlighted ways in which this would continue to evolve in the future.\n- Riana [discussed](https://youtu.be/O3t8TwWeli0) a recent paper of hers in which she evaluated the extent to which papers in social learning are able to be reproduced. \n\n\n### Invited talks\n\n- Amber Simpson discussed the repeatability and reproducibility of imaging biomarkers.\n- Andrés Cruz discussed an RStudio addin to supervise fuzzy joins. \n- Annie Collins discussed the extent of markers of open code and open data in medRxiv.\n- Emily Riederer discussed `convo` R package, which aids in the creation, upkeep, and application of controlled vocabularies.\n- Florencia D'Andrea discussed ReproHack, which is a hackathon-style event focused on the reproducibility of research results. \n- Garret Christensen discussed a recent paper looking at survey evidence on attitudes, norms and behavior in the social sciences towards open science. \n- Jake Bowers discussed proposals to adjust scientific norms of reproducibility and pre-registration to the policy context.\n- John Blischak discussed the `workflowr` R package\n- Julia Schulte-Cloos introduced a template package in R that allows users without any prior knowledge of R Markdown to implement reproducible research practices in their scientific workflows. \n- Lauren Kennedy discussed case studies of how and where challenges with preparing survey data appear in practice. \n- Larry Fenn and Meghan Hoyer discussed AP DataKit, which is an open-source command-line tool designed to better structure and manage projects, and more generally, talk about creating sane, reproducible workflows.\n- Mauricio Vargas Sepúlveda and Nicolas Didier discussed an attempt to analyze the nature and quality of civil society organizations' contributions to develop evidence for policymaking process from reproducibility perspective.  \n- Monica Alexander discussed some brief reflections from research, consulting, and teaching experiences that have led to overcoming barriers to sharing code and to help others do the same.  \n- Nancy Reid discussed whether p-values are contributing to a crisis in replicability and reproducibility, with emphasis on the role of inferential theory in helping to clarify the arguments.\n- Nick Radcliffe discussed an approach to the challenges of ensuring the correctness and robustness of results in an environment where neither code nor input data can be opened up for review and even outputs need to be subject to disclosure control to reduce further any risks to privacy. \n- Radu Craiu discussed reproducibility in the context of statistical sciences.\n- Ryan Briggs discussed how 'o-ring' production functions work and draws out lessons for applied researchers.\n- Sharla Gelfand discussed what components are needed to make a good reproducible example to maximize your ability to get help (and to help yourself!), strategies for coming up with an example and testing its reproducibility, and why you should care about making one.\n- Shemra Rizzo shared her experience working towards reliable, replicable and reproducible studies using EHR licensed data.\n- Shiro Kuriwaki showed how new features of the [dataverse](https://github.com/IQSS/dataverse-client-r) R package facilitate reproducibility in empirical, substantive projects. \n- Simeon Carstens gave an introduction to Nix, show in a live demo how to set up a fully reproducible software environment and compare Nix to existing solutions such as virtual environments and Docker.\n- Tiffany Timbers presented examples of how UBC deeply motivate, effectively instruct and provide ample practice opportunities to our Master of Data Science students to effectively engage them in learning about reproducibility.\n- Tom Barton reproduced Surridge, 2016, 'Education and liberalism: pursuing the link', *Oxford Review of Education*, 42:2, pp. 146-164, using the 1970 British Cohort Study (BCS70), instead using a difference-in-difference regression approach with more waves of data. \n- Tyler Girard discussed how individual and group exercises centered around the replication of existing datasets and analyses offer a flexible tool for experiential learning. \n- Wendy Duff discussed reproducibility in the context of information.\n- Wijdan Tariq undertook a narrow replication of Caicedo, 2019, 'The Mission: Human Capital Transmission, Economic Persistence, and Culture in South America', *Quarterly Journal of Economics*\n- Yanbo Tang showed that commonly held beliefs regarding the distribution of p-values are misleading when the variance or location of the test statistic are not well-calibrated or when the higher order cumulants of the test statistic are not negligible. \n\n\n## Attendance\n\n```{r,, warning = FALSE, message = FALSE, echo=FALSE}\nlibrary(tidyverse)\n\nread_csv(\"attendence.csv\") %>% \n  mutate(Day = if_else(Day == 1, \"Thursday\", \"Friday\")) %>% \n  ggplot() +\n  geom_point(aes(x = Check, y = Number, color = Day)) +\n  facet_wrap(vars(Type)) +\n  theme_classic() + \n  scale_color_brewer(palette = \"Set1\")\n```\n\n\n\n\n## What worked\n\n- Undergraduate participation. I integrated two undergrad presentations into the main content. Both were exceptional and received very well by the audience.\n- YouTube livestream. I only added this at the last minute because I was worried we might go over the 300-person limit in Zoom. In the end we didn't have a worry about that, but the livestream was very popular. Some people said it was because that way they could keep it on in the background while doing other things (YouTube has better volume control than Zoom).\n- Questions. There was some concern about a lack of time for questions, but in general folks were hesitant to ask questions.\n\n\n## What didn't\n\n- I needed more chairs.\n- More organization.\n- Slack was okay.\n- We didn't really do any 'networking' type events.\n- Funding.s\n- We needed more time.\n\n## Next steps\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":{"distill::distill_article":{"self_contained":false,"toc":true,"toc_depth":3}},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"the-toronto-workshop-on-reproducibility.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Danger","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.266","theme":"cosmo","title":"The Toronto Workshop on Reproducibility","description":"Notes and reflections on a workshop about reproducibility in applied statistics.\n","author":[{"name":"Rohan Alexander","url":{"rohanalexander.com":{}}}],"date":"2021-02-28","draft":true,"collections":{"posts":{"citations":false}}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}