<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.266">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Rohan Alexander">
<meta name="dcterms.date" content="2018-06-29">
<meta name="description" content="Each statement in Hansard needs to be classified by its topic. Sometimes Hansard includes titles that make the topic clear. But not every statement has a title and the titles do not always define topics in a well-defined and consistent way. One way to get consistent estimates of the topics of each statement in Hansard is to use the latent Dirichlet allocation (LDA) method of Blei, Ng, Jordan, Blei, Ng, and Jordan (2003), as implemented by the R package ‘topicmodels’ by Grun Grün and Hornik (2011).">

<title>Rohan Alexander - Topic Modelling - Theory</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Rohan Alexander</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-events" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Events</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-events">    
        <li>
    <a class="dropdown-item" href="../../events-tdw.html" rel="" target="">
 <span class="dropdown-text">Toronto Data Workshop</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../events-llms_colloquium.html" rel="" target="">
 <span class="dropdown-text">Colloquium on Applications of LLMs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../events-reproducibility.html" rel="" target="">
 <span class="dropdown-text">Toronto Workshop on Reproducibility</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../events-software.html" rel="" target="">
 <span class="dropdown-text">Conference on statistical software</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-teaching" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Teaching</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-teaching">    
        <li>
    <a class="dropdown-item" href="../../teaching-data_science_foundations.html" rel="" target="">
 <span class="dropdown-text">Data science foundations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../teaching-ethics_and_ds.html" rel="" target="">
 <span class="dropdown-text">Ethics and data science</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../teaching-inf2178.html" rel="" target="">
 <span class="dropdown-text">Experimental design for data science</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../teaching-history_of_statistics.html" rel="" target="">
 <span class="dropdown-text">History of statistics and data sciences</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../teaching-sta302.html" rel="" target="">
 <span class="dropdown-text">Methods of Data Analysis I</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../teaching-modeling.html" rel="" target="">
 <span class="dropdown-text">Introduction to Modeling</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../teaching-nlp.html" rel="" target="">
 <span class="dropdown-text">Natural language processing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../teaching-sta304.html" rel="" target="">
 <span class="dropdown-text">Surveys, sampling, and observational data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../teaching-inf312.html" rel="" target="">
 <span class="dropdown-text">Worlds become data</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-misc" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Misc</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-misc">    
        <li>
    <a class="dropdown-item" href="../../bookshelf.html" rel="" target="">
 <span class="dropdown-text">Bookshelf</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../blog.html" rel="" target="">
 <span class="dropdown-text">Blog</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../recs.html" rel="" target="">
 <span class="dropdown-text">Recommendations</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../pdfs/cv-academic-Rohan_Alexander.pdf" rel="" target="">
 <span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/RohanAlexander" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/RohanAlexander" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:rohan.alexander@utoronto.ca" rel="" target=""><i class="bi bi-envelope" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#document-generation-process" id="toc-document-generation-process" class="nav-link" data-scroll-target="#document-generation-process">Document generation process</a></li>
  <li><a href="#analysis-process" id="toc-analysis-process" class="nav-link" data-scroll-target="#analysis-process">Analysis process</a></li>
  <li><a href="#warnings-and-extensions" id="toc-warnings-and-extensions" class="nav-link" data-scroll-target="#warnings-and-extensions">Warnings and extensions</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Topic Modelling - Theory</h1>
</div>

<div>
  <div class="description">
    <p>Each statement in Hansard needs to be classified by its topic. Sometimes Hansard includes titles that make the topic clear. But not every statement has a title and the titles do not always define topics in a well-defined and consistent way. One way to get consistent estimates of the topics of each statement in Hansard is to use the latent Dirichlet allocation (LDA) method of Blei, Ng, Jordan, <span class="citation" data-cites="Blei2003latent">Blei, Ng, and Jordan (<a href="#ref-Blei2003latent" role="doc-biblioref">2003</a>)</span>, as implemented by the R package ‘topicmodels’ by Grun <span class="citation" data-cites="Grun2011">Grün and Hornik (<a href="#ref-Grun2011" role="doc-biblioref">2011</a>)</span>.</p>
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Rohan Alexander </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 29, 2018</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p><em>These are notes that I put together in the process of trying to understand how topic modelling works with a view to applying it to Australia’s Hansard. There are undoubtedly mistakes and aspects that are unclear. Please get in touch if you have any suggestions.</em></p>
<section id="overview" class="level1">
<h1>Overview</h1>
<p>Each statement in Hansard needs to be classified by its topic. Sometimes Hansard includes titles that make the topic clear. But not every statement has a title and the titles do not always define topics in a well-defined and consistent way. One way to get consistent estimates of the topics of each statement in Hansard is to use the latent Dirichlet allocation (LDA) method of <span class="citation" data-cites="Blei2003latent">Blei, Ng, and Jordan (<a href="#ref-Blei2003latent" role="doc-biblioref">2003</a>)</span>, as implemented by the R package ‘topicmodels’ by <span class="citation" data-cites="Grun2011">Grün and Hornik (<a href="#ref-Grun2011" role="doc-biblioref">2011</a>)</span>.</p>
<p>The key assumption behind the LDA method is that each statement, ‘a document’, in Hansard is made by a speaker who decides the topics they would like to talk about in that document, and then chooses words, ‘terms’, that are appropriate to those topics. A topic could be thought of as a collection of terms, and a document as a collection of topics. The topics are not specified <em>ex ante</em>; they are an outcome of the method. Terms are not necessarily unique to a particular topic, and a document could be about more than one topic. This provides more flexibility than other approaches such as a strict word count method. The goal is to have the words found in Hansard group themselves to define topics.</p>
</section>
<section id="document-generation-process" class="level1">
<h1>Document generation process</h1>
<p>As applied to Hansard, the LDA method considers each statement to be a result of a process where a politician first chooses the topics they want to speak about. After choosing the topics, the speaker then chooses appropriate words to use for each of those topics.</p>
<p>More generally, the LDA topic model works by considering each document as having been generated by some probability distribution over topics. For instance, if there were five topics and two documents, then the first document may be comprised mostly of the first few topics; the other document may be mostly about the final few topics (Figure @ref(fig:topicsoverdocuments)).</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="topic_modelling-theory_files/figure-html/topicsoverdocuments-1.png" class="quarto-discovered-preview-image img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Probability distributions over topics</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="topic_modelling-theory_files/figure-html/topicsoverdocuments-2.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Probability distributions over topics</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Similarly, each topic could be considered a probability distribution over terms. To choose the terms used in each document the speaker picks terms from each topic in the appropriate proportion. For instance, if there were ten terms, then one topic could be defined by giving more weight to terms related to immigration; and some other topic may give more weight to terms related to the economy (Figure @ref(fig:topicsoverterms)).</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="topic_modelling-theory_files/figure-html/topicsoverterms-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Probability distributions over terms</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="topic_modelling-theory_files/figure-html/topicsoverterms-2.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Probability distributions over terms</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Following <span class="citation" data-cites="BleiLafferty2009">Blei and Lafferty (<a href="#ref-BleiLafferty2009" role="doc-biblioref">2009</a>)</span>, <span class="citation" data-cites="blei2012">Blei (<a href="#ref-blei2012" role="doc-biblioref">2012</a>)</span> and <span class="citation" data-cites="GriffithsSteyvers2004">Griffiths and Steyvers (<a href="#ref-GriffithsSteyvers2004" role="doc-biblioref">2004</a>)</span>, the process by which a document is generated is more formally considered to be:</p>
<ol type="1">
<li>There are <span class="math inline">\(1, 2, \dots, k, \dots, K\)</span> topics and the vocabulary consists of <span class="math inline">\(1, 2, \dots, V\)</span> terms. For each topic, decide the terms that the topic uses by randomly drawing distributions over the terms. The distribution over the terms for the <span class="math inline">\(k\)</span>th topic is <span class="math inline">\(\beta_k\)</span>. Typically a topic would be a small number of terms and so the Dirichlet distribution with hyperparameter <span class="math inline">\(0&lt;\eta&lt;1\)</span> is used: <span class="math inline">\(\beta_k \sim \mbox{Dirichlet}(\eta)\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Strictly, <span class="math inline">\(\eta\)</span> is actually a vector of hyperparameters, one for each <span class="math inline">\(K\)</span>, but in practice they all tend to be the same value.</li>
<li>Decide the topics that each document will cover by randomly drawing distributions over the <span class="math inline">\(K\)</span> topics for each of the <span class="math inline">\(1, 2, \dots, d, \dots, D\)</span> documents. The topic distributions for the <span class="math inline">\(d\)</span>th document are <span class="math inline">\(\theta_d\)</span>, and <span class="math inline">\(\theta_{d,k}\)</span> is the topic distribution for topic <span class="math inline">\(k\)</span> in document <span class="math inline">\(d\)</span>. Again, the Dirichlet distribution with the hyperparameter <span class="math inline">\(0&lt;\alpha&lt;1\)</span> is used here because usually a document would only cover a handful of topics: <span class="math inline">\(\theta_d \sim \mbox{Dirichlet}(\alpha)\)</span>. Again, strictly <span class="math inline">\(\alpha\)</span> is vector of length <span class="math inline">\(K\)</span> of hyperparameters, but in practice each is usually the same value.</li>
<li>If there are <span class="math inline">\(1, 2, \dots, n, \dots, N\)</span> terms in the <span class="math inline">\(d\)</span>th document, then to choose the <span class="math inline">\(n\)</span>th term, <span class="math inline">\(w_{d, n}\)</span>:
<ol type="a">
<li>Randomly choose a topic for that term <span class="math inline">\(n\)</span>, in that document <span class="math inline">\(d\)</span>, <span class="math inline">\(z_{d,n}\)</span>, from the multinomial distribution over topics in that document, <span class="math inline">\(z_{d,n} \sim \mbox{Multinomial}(\theta_d)\)</span>.</li>
<li>Randomly choose a term from the relevant multinomial distribution over the terms for that topic, <span class="math inline">\(w_{d,n} \sim \mbox{Multinomial}(\beta_{z_{d,n}})\)</span>.</li>
</ol></li>
</ol>
<p>Given this set-up, the joint distribution for the variables is (<span class="citation" data-cites="blei2012">Blei (<a href="#ref-blei2012" role="doc-biblioref">2012</a>)</span>, p.6): <span class="math display">\[p(\beta_{1:K}, \theta_{1:D}, z_{1:D, 1:N}, w_{1:D, 1:N}) = \prod^{K}_{i=1}p(\beta_i) \prod^{D}_{d=1}p(\theta_d) \left(\prod^N_{n=1}p(z_{d,n}|\theta_d)p\left(w_{d,n}|\beta_{1:K},z_{d,n}\right) \right).\]</span></p>
<p>Based on this document generation process the analysis problem, discussed in the next section, is to compute a posterior over <span class="math inline">\(\beta_{1:K}\)</span> and <span class="math inline">\(\theta_{1:D}\)</span>, given <span class="math inline">\(w_{1:D, 1:N}\)</span>. This is intractable directly, but can be approximated (<span class="citation" data-cites="GriffithsSteyvers2004">Griffiths and Steyvers (<a href="#ref-GriffithsSteyvers2004" role="doc-biblioref">2004</a>)</span> and <span class="citation" data-cites="blei2012">Blei (<a href="#ref-blei2012" role="doc-biblioref">2012</a>)</span>).</p>
</section>
<section id="analysis-process" class="level1">
<h1>Analysis process</h1>
<p>After the documents are created, they are all that we have to analyse. The term usage in each document, <span class="math inline">\(w_{1:D, 1:N}\)</span>, is observed, but the topics are hidden, or ‘latent’. We do not know the topics of each document, nor how terms defined the topics. That is, we do not know the probability distributions of Figures @ref(fig:topicsoverdocuments) or @ref(fig:topicsoverterms). In a sense we are trying to reverse the document generation process – we have the terms and we would like to discover the topics.</p>
<p>If the earlier process around how the documents were generated is assumed and we observe the terms in each document, then we can obtain estimates of the topics (<span class="citation" data-cites="SteyversGriffiths2006">Steyvers and Griffiths (<a href="#ref-SteyversGriffiths2006" role="doc-biblioref">2006</a>)</span>). The outcomes of the LDA process are probability distributions and these define the topics. Each term will be given a probability of being a member of a particular topic, and each document will be given a probability of being about a particular topic. That is, we are trying to calculate the posterior distribution of the topics given the terms observed in each document (<span class="citation" data-cites="blei2012">Blei (<a href="#ref-blei2012" role="doc-biblioref">2012</a>)</span>, p.7): <span class="math display">\[p(\beta_{1:K}, \theta_{1:D}, z_{1:D, 1:N} | w_{1:D, 1:N}) = \frac{p\left(\beta_{1:K}, \theta_{1:D}, z_{1:D, 1:N}, w_{1:D, 1:N}\right)}{p(w_{1:D, 1:N})}.\]</span></p>
<p>The initial practical step when implementing LDA given a corpus of documents is to remove ‘stop words’. These are words that are common, but that don’t typically help to define topics. There is a general list of stop words such as: “a”; “a’s”; “able”; “about”; “above”… An additional list of words that are commonly found in Hansard, but likely don’t help define topics is added to the general list. These additions include words such as: “act”; “amendment”; “amount”; “australia”; “australian”; “bill”… A full list will be available in a follow up post going through an example with R code. We also remove punctuation and capitalisation. The documents need to then be transformed into a document-term-matrix. This is essentially a table with a column of the number of times each term appears in each document.</p>
<p>After the dataset is ready, the R package ‘topicmodels’ by <span class="citation" data-cites="Grun2011">Grün and Hornik (<a href="#ref-Grun2011" role="doc-biblioref">2011</a>)</span> can be used to implement LDA and approximate the posterior. It does this using Gibbs sampling or the variational expectation-maximization algorithm. Following <span class="citation" data-cites="SteyversGriffiths2006">Steyvers and Griffiths (<a href="#ref-SteyversGriffiths2006" role="doc-biblioref">2006</a>)</span> and <span class="citation" data-cites="Darling2011">Darling (<a href="#ref-Darling2011" role="doc-biblioref">2011</a>)</span>, the Gibbs sampling process attempts to find a topic for a particular term in a particular document, given the topics of all other terms for all other documents. Broadly, it does this by first assigning every term in every document to a random topic, specified by Dirichlet priors with <span class="math inline">\(\alpha = \frac{50}{K}\)</span> and <span class="math inline">\(\eta = 0.1\)</span> (<span class="citation" data-cites="SteyversGriffiths2006">Steyvers and Griffiths (<a href="#ref-SteyversGriffiths2006" role="doc-biblioref">2006</a>)</span> recommends <span class="math inline">\(\eta = 0.01\)</span>), where <span class="math inline">\(\alpha\)</span> refers to the distribution over topics and <span class="math inline">\(\eta\)</span> refers to the distribution over terms (<span class="citation" data-cites="Grun2011">Grün and Hornik (<a href="#ref-Grun2011" role="doc-biblioref">2011</a>)</span>, p.7). It then selects a particular term in a particular document and assigns it to a new topic based on the conditional distribution where the topics for all other terms in all documents are taken as given (<span class="citation" data-cites="Grun2011">Grün and Hornik (<a href="#ref-Grun2011" role="doc-biblioref">2011</a>)</span>, p.6): <span class="math display">\[p(z_{d, n}=k | w_{1:D, 1:N}, z'_{d, n}) \propto \frac{\lambda'_{n\rightarrow k}+\eta}{\lambda'_{.\rightarrow k}+V\eta} \frac{\lambda'^{(d)}_{n\rightarrow k}+\alpha}{\lambda'^{(d)}_{-i}+K\alpha} \]</span> where <span class="math inline">\(z'_{d, n}\)</span> refers to all other topic assignments; <span class="math inline">\(\lambda'_{n\rightarrow k}\)</span> is a count of how many other times that term has been assigned to topic <span class="math inline">\(k\)</span>; <span class="math inline">\(\lambda'_{.\rightarrow k}\)</span> is a count of how many other times that any term has been assigned to topic <span class="math inline">\(k\)</span>; <span class="math inline">\(\lambda'^{(d)}_{n\rightarrow k}\)</span> is a count of how many other times that term has been assigned to topic <span class="math inline">\(k\)</span> in that particular document; and <span class="math inline">\(\lambda'^{(d)}_{-i}\)</span> is a count of how many other times that term has been assigned in that document. Once <span class="math inline">\(z_{d,n}\)</span> has been estimated, then estimates for the distribution of words into topics and topics into documents can be backed out.</p>
<p>This conditional distribution assigns topics depending on how often a term has been assigned to that topic previously, and how common the topic is in that document (<span class="citation" data-cites="SteyversGriffiths2006">Steyvers and Griffiths (<a href="#ref-SteyversGriffiths2006" role="doc-biblioref">2006</a>)</span>). The initial random allocation of topics means that the results of early passes through the corpus of document are poor, but given enough time the algorithm converges to an appropriate estimate.</p>
</section>
<section id="warnings-and-extensions" class="level1">
<h1>Warnings and extensions</h1>
<p>The choice of the number of topics, <em>k</em>, affects the results, and must be specified <em>a priori</em>. If there is a strong reason for a particular number, then this can be used. Otherwise, one way to choose an appropriate number is to use a test and training set process. Essentially, this means running the process on a variety of possible values for <em>k</em> and then picking an appropriate value that performs well.</p>
<p>One weakness of the LDA method is that it considers a ‘bag of words’ where the order of those words does not matter (<span class="citation" data-cites="blei2012">Blei (<a href="#ref-blei2012" role="doc-biblioref">2012</a>)</span>). It is possible to extend the model to reduce the impact of the bag-of-words assumption and add conditionality to word order. Additionally, alternatives to the Dirichlet distribution can be used to extend the model to allow for correlation. For instance, in Hansard topics related the army may be expected to be more commonly found with topics related to the navy, but less commonly with topics related to banking.</p>
</section>
<section id="references" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-blei2012" class="csl-entry" role="listitem">
Blei, David M. 2012. <span>“Probabilistic Topic Models.”</span> <em>Communications of the ACM</em> 55 (4): 77–84.
</div>
<div id="ref-BleiLafferty2009" class="csl-entry" role="listitem">
Blei, David M, and John D Lafferty. 2009. <span>“Topic Models.”</span> In <em>Text Mining</em>, 101–24. Chapman; Hall/CRC.
</div>
<div id="ref-Blei2003latent" class="csl-entry" role="listitem">
Blei, David M, Andrew Y Ng, and Michael I Jordan. 2003. <span>“Latent Dirichlet Allocation.”</span> <em>Journal of Machine Learning Research</em> 3 (Jan): 993–1022.
</div>
<div id="ref-Darling2011" class="csl-entry" role="listitem">
Darling, William M. 2011. <span>“A Theoretical and Practical Implementation Tutorial on Topic Modeling and Gibbs Sampling.”</span> In <em>Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</em>, 642–47.
</div>
<div id="ref-GriffithsSteyvers2004" class="csl-entry" role="listitem">
Griffiths, Thomas, and Mark Steyvers. 2004. <span>“Finding Scientific Topics.”</span> <em>PNAS</em> 101: 5228–35.
</div>
<div id="ref-Grun2011" class="csl-entry" role="listitem">
Grün, Bettina, and Kurt Hornik. 2011. <span>“<span class="nocase">topicmodels</span>: An <span>R</span> Package for Fitting Topic Models.”</span> <em>Journal of Statistical Software</em> 40 (13): 1–30. <a href="https://doi.org/10.18637/jss.v040.i13">https://doi.org/10.18637/jss.v040.i13</a>.
</div>
<div id="ref-SteyversGriffiths2006" class="csl-entry" role="listitem">
Steyvers, Mark, and Tom Griffiths. 2006. <span>“Probabilistic Topic Models.”</span> In <em>Latent Semantic Analysis: A Road to Meaning</em>, edited by T. Landauer, D McNamara, S. Dennis, and W. Kintsch.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>The Dirichlet distribution is a variation of the beta distribution that is commonly used as a prior for categorical and multinomial variables. If there are just two categories, then the Dirichlet and the beta distributions are the same. In the special case of a symmetric Dirichlet distribution, <span class="math inline">\(\eta=1\)</span>, it is equivalent to a uniform distribution. If <span class="math inline">\(\eta&lt;1\)</span>, then the distribution is sparse and concentrated on a smaller number of the values, and this number decreases as <span class="math inline">\(\eta\)</span> decreases. A hyperparameter is a parameter of a prior distribution.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>